# -*- coding: utf-8 -*-
"""Copy of convolutional_neural_network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QigDTBu0rbcI4mq57hKSFb0xgWX10diH

# Convolutional Neural Network

### Importing the libraries
"""

import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator

# Specify the path to the zip file
zip_file_path = '/content/dataset.zip'  # Adjust the path accordingly

# Specify the directory where you want to extract the contents
extracted_dir = '/content/dataset'  # Adjust the path accordingly

# Run the unzip command
!unzip -q {zip_file_path} -d {extracted_dir}

print(f"File '{zip_file_path}' successfully extracted to '{extracted_dir}'.")

tf.__version__

"""## Part 1 - Data Preprocessing

### Preprocessing the Training set
"""

train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)
training_set = train_datagen.flow_from_directory('/content/dataset/dataset/training_set',
                                                 target_size = (64, 64),
                                                 batch_size = 32,
                                                 class_mode = 'binary')

"""### Preprocessing the Test set"""

test_datagen = ImageDataGenerator(rescale = 1./255)
test_set = test_datagen.flow_from_directory('/content/dataset/dataset/test_set',
                                            target_size = (64, 64),
                                            batch_size = 32,
                                            class_mode = 'binary')

"""## Part 2 - Building the CNN

### Initialising the CNN
"""

cnn = tf.keras.models.Sequential()

"""### Step 1 - Convolution"""

cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))

"""### Step 2 - Pooling"""

cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))

"""### Adding a second convolutional layer"""

cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))

"""### Step 3 - Flattening"""

cnn.add(tf.keras.layers.Flatten())

"""### Step 4 - Full Connection"""

cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))

"""### Step 5 - Output Layer"""

cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

"""## Part 3 - Training the CNN

### Compiling the CNN
"""

cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

"""### Training the CNN on the Training set and evaluating it on the Test set"""

cnn.fit(x = training_set, validation_data = test_set, epochs = 25)

"""## Part 4 - Making a single prediction"""

import numpy as np
from keras.preprocessing import image
test_image = image.load_img('/content/dataset/dataset/test_set/unticked/images (10).png', target_size = (64, 64))
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis = 0)
result = cnn.predict(test_image)
training_set.class_indices
if result[0][0] == 1:
  prediction = 'unticked'
else:
  prediction = 'ticked'

print(prediction)

import os

save_dir = '/content/saved_models'
if not os.path.exists(save_dir):
    os.makedirs(save_dir)

cnn.save(os.path.join(save_dir, 'my_cnn_model'))

!zip -r /content/saved_models.zip /content/saved_models

from google.colab import files

files.download("/content/saved_models.zip")